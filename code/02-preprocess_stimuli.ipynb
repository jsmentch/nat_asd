{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to extract 0.8s (TR) spaced image frames and audio clips from a movie stimulus for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try pliers conda env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "#from dotenv import load_dotenv\n",
    "#from utils import setup_logging\n",
    "#import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim='DM'\n",
    "video_path=f'../data/{stim}.mp4'\n",
    "save_dir=f'../data/{stim}_frames/'\n",
    "TR=0.8 # how often to sample in seconds\n",
    "\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_rate = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "frames_to_skip = int(round(frame_rate*TR))\n",
    "\n",
    "frame_count = 0\n",
    "saved_frame_count = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop if we've reached the end of the video\n",
    "\n",
    "    if frame_count % frames_to_skip == 0:\n",
    "        output_frame_path = os.path.join(save_dir, f\"frame_{saved_frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(output_frame_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])  # Adjust the quality as needed\n",
    "        saved_frame_count += 1\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Release the video capture object\n",
    "video_capture.release()\n",
    "#logging.info(f\"Saved {saved_frame_count} frames from {video_path} to {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first convert TP.mp4 to a .mov since h264 codec not working with cv2\n",
    "#ffmpeg -i TP.mp4 -vcodec libx264 TP.mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim='TP'\n",
    "video_path=f'../data/{stim}.mov'\n",
    "save_dir=f'../data/{stim}_frames/'\n",
    "TR=0.8 # how often to sample in seconds\n",
    "\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_rate = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "frames_to_skip = int(round(frame_rate*TR))\n",
    "\n",
    "frame_count = 0\n",
    "saved_frame_count = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop if we've reached the end of the video\n",
    "\n",
    "    if frame_count % frames_to_skip == 0:\n",
    "        output_frame_path = os.path.join(save_dir, f\"frame_{saved_frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(output_frame_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])  # Adjust the quality as needed\n",
    "        saved_frame_count += 1\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Release the video capture object\n",
    "video_capture.release()\n",
    "#logging.info(f\"Saved {saved_frame_count} frames from {video_path} to {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use net2brain env\n",
    "#first turn the mp4s into .wavs for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim='TP'\n",
    "\n",
    "audio_data, sr = librosa.load(f'../data/{stim}.wav', sr=20000)\n",
    "clip_length = 2.0  # length of each clip in seconds\n",
    "step_size = 0.8  # step size in seconds (the HBN fMRI TR)\n",
    "\n",
    "# Calculate the number of samples for clip length and step size\n",
    "clip_samples = int(clip_length * sr)\n",
    "step_samples = int(step_size * sr)\n",
    "\n",
    "# Number of clips\n",
    "num_clips = int((len(audio_data) - clip_samples) / step_samples) + 1\n",
    "\n",
    "\n",
    "for i in range(num_clips):\n",
    "    start_sample = i * step_samples\n",
    "    end_sample = start_sample + clip_samples\n",
    "\n",
    "    # Extract clip\n",
    "    clip = audio_data[start_sample:end_sample]\n",
    "\n",
    "    # Save clip as .wav file\n",
    "    #librosa.write_wav(f'../../data/{stim}_clips/clip_{i:04d}.wav', clip, sr)\n",
    "    soundfile.write(f'../data/{stim}_clips/clip_{i:04d}.wav', clip, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
