{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to extract 0.8s (TR) spaced image frames and audio clips from a movie stimulus for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try pliers conda env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run video (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "#from dotenv import load_dotenv\n",
    "#from utils import setup_logging\n",
    "#import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### despicable me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim='DM'\n",
    "video_path=f'../data/{stim}.mp4'\n",
    "save_dir=f'../data/{stim}_frames/'\n",
    "TR=0.8 # how often to sample in seconds\n",
    "\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_rate = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "frames_to_skip = int(round(frame_rate*TR))\n",
    "\n",
    "frame_count = 0\n",
    "saved_frame_count = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop if we've reached the end of the video\n",
    "\n",
    "    if frame_count % frames_to_skip == 0:\n",
    "        output_frame_path = os.path.join(save_dir, f\"frame_{saved_frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(output_frame_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])  # Adjust the quality as needed\n",
    "        saved_frame_count += 1\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Release the video capture object\n",
    "video_capture.release()\n",
    "#logging.info(f\"Saved {saved_frame_count} frames from {video_path} to {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Present\n",
    "#first convert TP.mp4 to a .mov since h264 codec not working with cv2\n",
    "#ffmpeg -i TP.mp4 -vcodec libx264 TP.mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim='TP'\n",
    "video_path=f'../data/{stim}.mov'\n",
    "save_dir=f'../data/{stim}_frames/'\n",
    "TR=0.8 # how often to sample in seconds\n",
    "\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_rate = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "frames_to_skip = int(round(frame_rate*TR))\n",
    "\n",
    "frame_count = 0\n",
    "saved_frame_count = 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop if we've reached the end of the video\n",
    "\n",
    "    if frame_count % frames_to_skip == 0:\n",
    "        output_frame_path = os.path.join(save_dir, f\"frame_{saved_frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(output_frame_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])  # Adjust the quality as needed\n",
    "        saved_frame_count += 1\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Release the video capture object\n",
    "video_capture.release()\n",
    "#logging.info(f\"Saved {saved_frame_count} frames from {video_path} to {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Friends (Cneuromod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../data/friends_s01e01b_frames/ created.\n",
      "Directory ../data/friends_s01e02a_frames/ created.\n",
      "Directory ../data/friends_s01e02b_frames/ created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "friends_path='/nese/mit/group/sig/projects/cneuromod/cneuromod/friends/stimuli/s1'\n",
    "\n",
    "#stim='friends_s01e01a'\n",
    "for stim in ['friends_s01e01b','friends_s01e02a','friends_s01e02b']:\n",
    "    video_path=f'{friends_path}/{stim}.mkv'\n",
    "    save_dir=f'../data/{stim}_frames/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        # Create the directory\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"Directory {save_dir} created.\")\n",
    "    else:\n",
    "        print(f\"Directory {save_dir} already exists.\")\n",
    "\n",
    "    TR=1.49 # how often to sample in seconds\n",
    "\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_rate = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "    frames_to_skip = int(round(frame_rate*TR))\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_frame_count = 0\n",
    "\n",
    "\n",
    "    while True:\n",
    "        # Read the next frame from the video\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        if not ret:\n",
    "            break  # Break the loop if we've reached the end of the video\n",
    "\n",
    "        if frame_count % frames_to_skip == 0:\n",
    "            output_frame_path = os.path.join(save_dir, f\"frame_{saved_frame_count:04d}.jpg\")\n",
    "            cv2.imwrite(output_frame_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 100])  # Adjust the quality as needed\n",
    "            saved_frame_count += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    video_capture.release()\n",
    "    #logging.info(f\"Saved {saved_frame_count} frames from {video_path} to {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split into 0.8 second video clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video split successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def split_video(input_file, output_dir, segment_length=0.8):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Command to split the video using FFmpeg\n",
    "    ffmpeg_command = [\n",
    "        'ffmpeg',\n",
    "        '-v', 'error',  # Verbose output for errors\n",
    "        '-i', input_file,\n",
    "        '-c:v', 'libx264',  # Use H.264 codec for video re-encoding\n",
    "        '-c:a', 'aac',      # Use AAC codec for audio re-encoding\n",
    "        '-b:v', '1000k',    # Set video bitrate\n",
    "        '-b:a', '128k',     # Set audio bitrate\n",
    "        '-force_key_frames', f'expr:gte(t,n_forced*{segment_length})',  # Force keyframes at segment_length intervals\n",
    "        '-f', 'segment',\n",
    "        '-segment_time', str(segment_length),\n",
    "        '-reset_timestamps', '1',\n",
    "        os.path.join(output_dir, 'output%03d.mp4')\n",
    "    ]\n",
    "\n",
    "    # Run the command and capture output\n",
    "    result = subprocess.run(ffmpeg_command, capture_output=True, text=True)\n",
    "\n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error splitting video:\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "\n",
    "    print(\"Video split successfully.\")\n",
    "\n",
    "# Example usage\n",
    "input_video = '../data/DM.mp4'\n",
    "output_directory = '../data/DM_videos'\n",
    "split_video(input_video, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video split successfully.\n"
     ]
    }
   ],
   "source": [
    "#TP is a little messed up, do it a bit differently\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def split_video(input_file, output_dir, segment_length=0.8):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Command to split the video using FFmpeg\n",
    "    ffmpeg_command = [\n",
    "        'ffmpeg',\n",
    "        '-v', 'error',  # Verbose output for errors\n",
    "        '-i', input_file,\n",
    "        '-c:v', 'libx264',  # Use H.264 codec for video re-encoding\n",
    "        '-c:a', 'aac',      # Use AAC codec for audio re-encoding\n",
    "        '-b:v', '500k',     # Lower video bitrate to reduce buffering\n",
    "        '-b:a', '64k',      # Lower audio bitrate to reduce buffering\n",
    "        '-force_key_frames', f'expr:gte(t,n_forced*{segment_length})',  # Force keyframes at segment_length intervals\n",
    "        '-f', 'segment',\n",
    "        '-segment_time', str(segment_length),\n",
    "        '-reset_timestamps', '1',\n",
    "        '-max_muxing_queue_size', '1024',  # Increase the muxing queue size\n",
    "        os.path.join(output_dir, 'output%03d.mp4')\n",
    "    ]\n",
    "\n",
    "    # Run the command and capture output\n",
    "    result = subprocess.run(ffmpeg_command, capture_output=True, text=True)\n",
    "\n",
    "    # Check for errors\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error splitting video:\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "\n",
    "    print(\"Video split successfully.\")\n",
    "\n",
    "# Example usage\n",
    "# input_video = '../data/DM.mp4'\n",
    "# output_directory = '../data/DM_videos'\n",
    "# split_video(input_video, output_directory)\n",
    "\n",
    "\n",
    "input_video = '../data/TP.mp4'\n",
    "output_directory = '../data/TP_videos'\n",
    "split_video(input_video, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use net2brain env\n",
    "#first turn the mp4s into .wavs for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim='TP'\n",
    "\n",
    "audio_data, sr = librosa.load(f'../data/{stim}.wav', sr=20000)\n",
    "clip_length = 2.0  # length of each clip in seconds\n",
    "step_size = 0.8  # step size in seconds (the HBN fMRI TR)\n",
    "\n",
    "# Calculate the number of samples for clip length and step size\n",
    "clip_samples = int(clip_length * sr)\n",
    "step_samples = int(step_size * sr)\n",
    "\n",
    "# Number of clips\n",
    "num_clips = int((len(audio_data) - clip_samples) / step_samples) + 1\n",
    "\n",
    "\n",
    "for i in range(num_clips):\n",
    "    start_sample = i * step_samples\n",
    "    end_sample = start_sample + clip_samples\n",
    "\n",
    "    # Extract clip\n",
    "    clip = audio_data[start_sample:end_sample]\n",
    "\n",
    "    # Save clip as .wav file\n",
    "    #librosa.write_wav(f'../../data/{stim}_clips/clip_{i:04d}.wav', clip, sr)\n",
    "    soundfile.write(f'../data/{stim}_clips/clip_{i:04d}.wav', clip, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### friends\n",
    "save files as .wavs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "friends_path='/nese/mit/group/sig/projects/cneuromod/cneuromod/friends/stimuli/s1'\n",
    "\n",
    "stim='friends_s01e01a'\n",
    "for stim in ['friends_s01e01b','friends_s01e02a','friends_s01e02b']:\n",
    "\n",
    "    input_file=f'{friends_path}/{stim}.mkv'\n",
    "    output_file=f'../data/{stim}.wav'\n",
    "\n",
    "    command = [\n",
    "        'ffmpeg',\n",
    "        '-i', input_file,\n",
    "        '-vn',\n",
    "        '-acodec', 'pcm_s16le',\n",
    "        '-ar', '44100',\n",
    "        '-ac', '2',\n",
    "        output_file\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"File converted and saved as {output_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stim='friends_s01e01a'\n",
    "for stim in ['friends_s01e01a','friends_s01e01b','friends_s01e02a','friends_s01e02b']:\n",
    "    \n",
    "    if not os.path.exists(f'../data/{stim}_clips/'):\n",
    "        os.makedirs(f'../data/{stim}_clips/')\n",
    "    \n",
    "    audio_data, sr = librosa.load(f'../data/{stim}.wav', sr=20000)\n",
    "    clip_length = 2.0  # length of each clip in seconds\n",
    "    step_size = 1.49  # step size in seconds (the HBN fMRI TR)\n",
    "\n",
    "    # Calculate the number of samples for clip length and step size\n",
    "    clip_samples = int(clip_length * sr)\n",
    "    step_samples = int(step_size * sr)\n",
    "\n",
    "    # Number of clips\n",
    "    num_clips = int((len(audio_data) - clip_samples) / step_samples) + 1\n",
    "\n",
    "\n",
    "    for i in range(num_clips):\n",
    "        start_sample = i * step_samples\n",
    "        end_sample = start_sample + clip_samples\n",
    "\n",
    "        # Extract clip\n",
    "        clip = audio_data[start_sample:end_sample]\n",
    "\n",
    "        # Save clip as .wav file\n",
    "        #librosa.write_wav(f'../../data/{stim}_clips/clip_{i:04d}.wav', clip, sr)\n",
    "        soundfile.write(f'../data/{stim}_clips/clip_{i:04d}.wav', clip, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
